{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training CNN Models\n",
    "\n",
    "We trained the optimized **VGG16** and **VGG16 with CBAM attention mechanism** models with the [7,000 unique sky\n",
    "photos](https://doi.org/10.5281/zenodo.7830131) of the occurrence or non-occurrence of falling meteors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import os\n",
    "import glob\n",
    "import shutil\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "from utils.dataset import DataHandler\n",
    "from utils.models import VGGModel\n",
    "from utils import evaluation\n",
    "from pathlib import Path\n",
    "import argparse\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "get_ipython().run_line_magic('matplotlib', 'inline')\n",
    "\n",
    "print(tf.__version__)\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "\n",
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "config = ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = InteractiveSession(config=config)\n",
    "\n",
    "if not os.path.exists('models'):\n",
    "    os.mkdir('models')\n",
    "    \n",
    "parser = argparse.ArgumentParser()\n",
    "args = parser.parse_args(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the 7.000 meteor dataset\n",
    "args.path_prefix = 'data/cropped24_images/'\n",
    "args.classes = ['nonmeteor', 'meteor'] # zero -> nonmeteor; one -> meteor\n",
    "args.image_size = (224, 224)\n",
    "args.seed = 2023\n",
    "\n",
    "np.random.seed(args.seed)\n",
    "tf.random.set_seed(args.seed)\n",
    "\n",
    "data_handler = DataHandler(args, path_prefix=args.path_prefix)\n",
    "df_images = data_handler.load_dataset(shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auxiliary functions\n",
    "def visualize_metrics(fold_no, acc, f1, sp, sn, tss, far, er, loss):\n",
    "    print(f'Test score for fold {fold_no+1}:')\n",
    "    print(f'\\tAcc: {acc}%')\n",
    "    print(f'\\tF1_: {f1}%')\n",
    "    print(f'\\tSp_: {sp}%')\n",
    "    print(f'\\tSn_: {sn}%')\n",
    "    print(f'\\tTSS: {tss}%')\n",
    "    print(f'\\tFAR: {far}%')\n",
    "    print(f'\\tER_: {er}')\n",
    "    print(f'\\tLoss: {loss}')\n",
    "    \n",
    "    \n",
    "def predict(model, data_gen):\n",
    "    y_test = data_gen.classes\n",
    "    y_pred = np.argmax(model.predict(data_gen), axis=1)\n",
    "    \n",
    "    acc = evaluation.accuracy(y_test, y_pred)\n",
    "    f1 = evaluation.f1_score(y_test, y_pred)\n",
    "    sp = evaluation.specificity(y_test, y_pred)\n",
    "    sn = evaluation.sensitivity(y_test, y_pred)\n",
    "    tss = evaluation.true_skill_statistic(y_test, y_pred)\n",
    "    far = evaluation.false_alarm_ratio(y_test, y_pred)\n",
    "    er = evaluation.error_rate(y_test, y_pred)\n",
    "    \n",
    "    return acc, f1, sp, sn, tss, far, er"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Training\n",
    "inputs = df_images['id']\n",
    "targets = df_images['label']\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    ")\n",
    "\n",
    "# Configurations\n",
    "image_size = (224, 224, 3)\n",
    "model_name = 'cbam' # baseline or cbam\n",
    "n_dense_layers = 16\n",
    "activation_func = 'relu'\n",
    "dropout = 0.2\n",
    "\n",
    "batchsize_training = 8\n",
    "batchsize_finetune = 32\n",
    "\n",
    "adamw_lr_training = 1e-05\n",
    "adamw_lr_finetune = 1e-04\n",
    "adamw_wd_training = 0.0005\n",
    "adamw_wd_finetune = 0.0005\n",
    "\n",
    "# Define per-fold score containers\n",
    "train_acc_per_fold = []\n",
    "train_f1_per_fold  = []\n",
    "train_sp_per_fold  = []\n",
    "train_sn_per_fold  = []\n",
    "train_tss_per_fold = []\n",
    "train_far_per_fold = []\n",
    "train_er_per_fold  = []\n",
    "train_loss_per_fold = []\n",
    "\n",
    "valid_acc_per_fold = []\n",
    "valid_f1_per_fold  = []\n",
    "valid_sp_per_fold  = []\n",
    "valid_sn_per_fold  = []\n",
    "valid_tss_per_fold = []\n",
    "valid_far_per_fold = []\n",
    "valid_er_per_fold  = []\n",
    "valid_loss_per_fold = []\n",
    "\n",
    "test_acc_per_fold = []\n",
    "test_f1_per_fold  = []\n",
    "test_sp_per_fold  = []\n",
    "test_sn_per_fold  = []\n",
    "test_tss_per_fold = []\n",
    "test_far_per_fold = []\n",
    "test_er_per_fold  = []\n",
    "test_loss_per_fold = []\n",
    "\n",
    "# Define the K-fold Cross Validator\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=False)\n",
    "for fold_no, (train, test) in enumerate(kfold.split(inputs, targets)):\n",
    "  \n",
    "    # == Generate a print ==\n",
    "    print('------------------------------------------------------------------------')\n",
    "    print(f'Training for fold {fold_no+1} ...')\n",
    "\n",
    "    # == Generate data ==\n",
    "    df_train = df_images.iloc[train]\n",
    "    df_test = df_images.iloc[test]\n",
    "    df_train, df_valid = train_test_split(df_train, test_size=0.2, stratify=df_train['label'], random_state=args.seed)\n",
    "    train_gen, valid_gen, test_gen = data_handler.generate_data(datagen, df_train, df_valid, df_test, batch_size=batchsize_training)\n",
    "\n",
    "    # == Checkpointer ==\n",
    "    checkpointer = tf.keras.callbacks.ModelCheckpoint(f'models/vgg_model_fold{fold_no+1}.h5', \n",
    "                                                      monitor=\"val_loss\",\n",
    "                                                      save_best_only=True, \n",
    "                                                      save_weights_only=False)\n",
    "    \n",
    "    # == Create model ==\n",
    "    vgg_builder = VGGModel(image_size=image_size, vgg_model='16')\n",
    "    if model_name == 'baseline':\n",
    "        model = vgg_builder.create_bachnorm_model(place_between_activation=False,\n",
    "                                                  n_layers=n_dense_layers,\n",
    "                                                  activation=activation_func,\n",
    "                                                  dropout=dropout)\n",
    "    elif model_name == 'cbam':\n",
    "        model = vgg_builder.create_cbam_model(n_layers=n_dense_layers,\n",
    "                                              activation=activation_func,\n",
    "                                              dropout=dropout)\n",
    "    \n",
    "    # == Training ==\n",
    "    optimizer = tf.keras.optimizers.experimental.AdamW(weight_decay=adamw_wd_training, learning_rate=adamw_lr_training)\n",
    "    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    history = model.fit(train_gen,\n",
    "                        validation_data=valid_gen,\n",
    "                        epochs=10)\n",
    "    \n",
    "    # == Fine tune ==\n",
    "    print('Fine tuning ...')\n",
    "    model.trainable = True\n",
    "    train_gen, valid_gen, test_gen = data_handler.generate_data(datagen, df_train, df_valid, df_test, batch_size=batchsize_finetune)\n",
    "    optimizer = tf.keras.optimizers.experimental.AdamW(weight_decay=adamw_wd_finetune, learning_rate=adamw_lr_finetune)\n",
    "    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    history = model.fit(train_gen,\n",
    "                        validation_data=valid_gen,\n",
    "                        epochs=50,\n",
    "                        callbacks=[checkpointer])\n",
    "\n",
    "    # == Generate metrics ==\n",
    "    print('Model evaluation ...')\n",
    "    model.load_weights(f'models-cropped/vgg_model_fold{fold_no+1}.h5')\n",
    "    train_gen, valid_gen, test_gen = data_handler.generate_data(datagen, df_train, df_valid, df_test, shuffle=False)\n",
    "    \n",
    "    # Train set\n",
    "    loss, acc_eval = model.evaluate(train_gen, verbose=0)\n",
    "    acc, f1, sp, sn, tss, far, er = predict(model, train_gen)\n",
    "    assert round(acc_eval, 2) == round(acc, 2)\n",
    "    train_acc_per_fold.append(acc)\n",
    "    train_f1_per_fold.append(f1)\n",
    "    train_sp_per_fold.append(sp)\n",
    "    train_sn_per_fold.append(sn)\n",
    "    train_tss_per_fold.append(tss)\n",
    "    train_far_per_fold.append(far)\n",
    "    train_er_per_fold.append(er)\n",
    "    train_loss_per_fold.append(loss)\n",
    "    \n",
    "    # Val set\n",
    "    loss, acc_eval = model.evaluate(valid_gen, verbose=0)\n",
    "    acc, f1, sp, sn, tss, far, er = predict(model, valid_gen)\n",
    "    assert round(acc_eval, 2) == round(acc, 2)\n",
    "    valid_acc_per_fold.append(acc)\n",
    "    valid_f1_per_fold.append(f1)\n",
    "    valid_sp_per_fold.append(sp)\n",
    "    valid_sn_per_fold.append(sn)\n",
    "    valid_tss_per_fold.append(tss)\n",
    "    valid_far_per_fold.append(far)\n",
    "    valid_er_per_fold.append(er)\n",
    "    valid_loss_per_fold.append(loss)\n",
    "    \n",
    "    # Test set\n",
    "    loss, acc_eval = model.evaluate(test_gen, verbose=0)\n",
    "    acc, f1, sp, sn, tss, far, er = predict(model, test_gen)\n",
    "    assert round(acc_eval, 2) == round(acc, 2)\n",
    "    test_acc_per_fold.append(acc)\n",
    "    test_f1_per_fold.append(f1)\n",
    "    test_sp_per_fold.append(sp)\n",
    "    test_sn_per_fold.append(sn)\n",
    "    test_tss_per_fold.append(tss)\n",
    "    test_far_per_fold.append(far)\n",
    "    test_er_per_fold.append(er)\n",
    "    test_loss_per_fold.append(loss)\n",
    "    \n",
    "    # Visualize test generalization metrics\n",
    "    visualize_metrics(fold_no, acc, f1, sp, sn, tss, far, er, loss)\n",
    "\n",
    "\n",
    "# == Provide average scores ==\n",
    "print('------------------------------------------------------------------------')\n",
    "print('Score per fold')\n",
    "for i in range(0, len(test_acc_per_fold)):\n",
    "    print('------------------------------------------------------------------------')\n",
    "    print(f'> Fold {i+1} - Loss: {test_loss_per_fold[i]} - Accuracy: {test_acc_per_fold[i]}%')\n",
    "print('------------------------------------------------------------------------')\n",
    "print('Average scores for all folds:')\n",
    "print(f'> Accuracy: {np.mean(test_acc_per_fold)} (+- {np.std(test_acc_per_fold)})')\n",
    "print(f'> Loss: {np.mean(test_loss_per_fold)}')\n",
    "print('------------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile results\n",
    "results_df = pd.DataFrame({'TRAIN_ACC':train_acc_per_fold, 'VALID_ACC':valid_acc_per_fold, 'TEST_ACC':test_acc_per_fold, \n",
    "                           'TRAIN_F1':train_f1_per_fold, 'VALID_F1':valid_f1_per_fold, 'TEST_F1':test_f1_per_fold,\n",
    "                           'TRAIN_SP':train_sp_per_fold, 'VALID_SP':valid_sp_per_fold, 'TEST_SP':test_sp_per_fold,\n",
    "                           'TRAIN_SN':train_sn_per_fold, 'VALID_SN':valid_sn_per_fold, 'TEST_SN':test_sn_per_fold,\n",
    "                           'TRAIN_TSS':train_tss_per_fold, 'VALID_TSS':valid_tss_per_fold, 'TEST_TSS':test_tss_per_fold,\n",
    "                           'TRAIN_FAR':train_far_per_fold, 'VALID_FAR':valid_far_per_fold, 'TEST_FAR':test_far_per_fold,\n",
    "                           'TRAIN_ER':train_er_per_fold, 'VALID_ER':valid_er_per_fold, 'TEST_ER':test_er_per_fold,\n",
    "                           'TRAIN_LOSS':train_loss_per_fold, 'VALID_LOSS':valid_loss_per_fold, 'TEST_LOSS':test_loss_per_fold})\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to disk\n",
    "results_df.to_csv(f'results/training_{model_name}_results.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
